[root@EQVLWSO2APSIT15-Master1 images]# kubectl get po -n kube-system -o wide
NAME                                              READY   STATUS       RESTARTS      AGE   IP             NODE                      NOMINATED NODE   READINESS GATES
calico-kube-controllers-6ffb5df975-bnxtg          0/1     Pending      0             16s   <none>         <none>                    <none>           <none>
calico-node-wbst5                                 0/1     Init:Error   2 (14s ago)   16s   10.57.12.120   eqvlwso2apsit15-master1   <none>           <none>
coredns-66bc5c9577-cwzzb                          0/1     Pending      0             16s   <none>         <none>                    <none>           <none>
coredns-66bc5c9577-xjckk                          0/1     Pending      0             16s   <none>         <none>                    <none>           <none>
etcd-eqvlwso2apsit15-master1                      1/1     Running      0             99m   10.57.12.120   eqvlwso2apsit15-master1   <none>           <none>
kube-apiserver-eqvlwso2apsit15-master1            1/1     Running      0             99m   10.57.12.120   eqvlwso2apsit15-master1   <none>           <none>
kube-controller-manager-eqvlwso2apsit15-master1   1/1     Running      0             99m   10.57.12.120   eqvlwso2apsit15-master1   <none>           <none>
kube-proxy-nzlfj                                  1/1     Running      0             99m   10.57.12.120   eqvlwso2apsit15-master1   <none>           <none>
kube-scheduler-eqvlwso2apsit15-master1            1/1     Running      0             99m   10.57.12.120   eqvlwso2apsit15-master1   <none>           <none>
[root@EQVLWSO2APSIT15-Master1 images]# kubectl describe po coredns-66bc5c9577-xjckk -n kube-system
Name:                 coredns-66bc5c9577-xjckk
Namespace:            kube-system
Priority:             2000000000
Priority Class Name:  system-cluster-critical
Service Account:      coredns
Node:                 <none>
Labels:               k8s-app=kube-dns
                      pod-template-hash=66bc5c9577
Annotations:          <none>
Status:               Pending
IP:
IPs:                  <none>
Controlled By:        ReplicaSet/coredns-66bc5c9577
Containers:
  coredns:
    Image:       registry.k8s.io/coredns/coredns:v1.12.1
    Ports:       53/UDP (dns), 53/TCP (dns-tcp), 9153/TCP (metrics), 8080/TCP (liveness-probe), 8181/TCP (readiness-probe)
    Host Ports:  0/UDP (dns), 0/TCP (dns-tcp), 0/TCP (metrics), 0/TCP (liveness-probe), 0/TCP (readiness-probe)
    Args:
      -conf
      /etc/coredns/Corefile
    Limits:
      memory:  170Mi
    Requests:
      cpu:        100m
      memory:     70Mi
    Liveness:     http-get http://:liveness-probe/health delay=60s timeout=5s period=10s #success=1 #failure=5
    Readiness:    http-get http://:readiness-probe/ready delay=0s timeout=1s period=10s #success=1 #failure=3
    Environment:  <none>
    Mounts:
      /etc/coredns from config-volume (ro)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-wzgx6 (ro)
Conditions:
  Type           Status
  PodScheduled   False
Volumes:
  config-volume:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      coredns
    Optional:  false
  kube-api-access-wzgx6:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    Optional:                false
    DownwardAPI:             true
QoS Class:                   Burstable
Node-Selectors:              kubernetes.io/os=linux
Tolerations:                 CriticalAddonsOnly op=Exists
                             node-role.kubernetes.io/control-plane:NoSchedule
                             node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason            Age   From               Message
  ----     ------            ----  ----               -------
  Warning  FailedScheduling  41s   default-scheduler  0/1 nodes are available: 1 node(s) had untolerated taint(s). no new claims to deallocate, preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling.
[root@EQVLWSO2APSIT15-Master1 images]#
